{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Technocolab Internship Task 1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOH+Qy+cadpOQ3Hky2yu+JL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gourab337/Technocolab_DL_Internship/blob/main/Technocolab_Internship_Task_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "707blMbPWCri"
      },
      "source": [
        "## Load given dataset (Dataset1.zip)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbbLVvdjZGWn",
        "outputId": "6bb05b16-2695-4c7e-ed84-e5cbc4aa7d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        }
      },
      "source": [
        "!pip install tensorflow==1.12.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 1.2MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 43.6MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (50.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.2.0)\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.12.2 tensorflow-1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7fsijZcVQBx",
        "outputId": "6d627de1-f441-435e-c675-6f458a73f26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "import tqdm\n",
        "import os\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#\n",
        "#  Script variables. Change these and observe\n",
        "#  how results change.\n",
        "#\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 2000\n",
        "\n",
        "#\n",
        "#  Script constants. Here we pull data available\n",
        "#  locally. The data contains both the sprites\n",
        "#  and the labels from the original MNIST dataset.\n",
        "#\n",
        "LOGDIR = \"mnist_example/\"\n",
        "LABELS = os.path.join(os.getcwd(), \"labels_1024.tsv\") #set file path\n",
        "SPRITES = os.path.join(os.getcwd(), \"sprite_1024.png\")  #set file path\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"Load data form the MNIST dataset into memory.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    TensorFlow object with dataset.\n",
        "    \"\"\"\n",
        "    if not (os.path.isfile(LABELS) and os.path.isfile(SPRITES)):\n",
        "        raise ValueError(\"\"\"\n",
        "            Necessary data files were not found. Make sure the files\n",
        "\n",
        "                * labels_1024.tsv\n",
        "                * sprite_1024.png\n",
        "\n",
        "            are available in the same location where you run this script.\n",
        "            \"\"\")\n",
        "\n",
        "    return tf.contrib.learn.datasets.mnist.read_data_sets(\n",
        "        train_dir=LOGDIR + \"data\", one_hot=True)\n",
        "\n",
        "\n",
        "def convolutional_layer(input, size_in, size_out, name=\"convolutional\"):\n",
        "    \"\"\"Convoluted layer.\n",
        "\n",
        "    Create the weights and biases distributions.\n",
        "    Also define the convolution and the activation function (ReLU).\n",
        "    Finally, we create some histogram summaries useful for TensorBoard.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in, size_out: int or float\n",
        "        Where to truncate the normal distribution.\n",
        "\n",
        "    name: str\n",
        "        Name to give the TensorFlow scope.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "\n",
        "        W = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"Weights\")\n",
        "        B = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
        "\n",
        "        convolution = tf.nn.conv2d(input, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "        activation = tf.nn.relu(convolution + B)\n",
        "\n",
        "        tf.summary.histogram(\"weights\", W)\n",
        "        tf.summary.histogram(\"biases\", B)\n",
        "        tf.summary.histogram(\"activations\", activation)\n",
        "\n",
        "        return tf.nn.max_pool(activation, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "\n",
        "def fully_connected_layer(input, size_in, size_out, name=\"fully_connected\"):\n",
        "    \"\"\"Fully connected layer.\n",
        "\n",
        "    This defines the fully connected layer.\n",
        "    Different from the convolution layer, this layer does not\n",
        "    perform a convolution but only defines an activation function.\n",
        "    That function is also different from the convolution layer\n",
        "    by multipliying the input data with its weights plus the biases,\n",
        "    which is a much simpler activation function than ReLU.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    size_in, size_out: int or float\n",
        "        Where to truncate the normal distribution.\n",
        "\n",
        "    name: str\n",
        "        Name to give the TensorFlow scope.\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        W = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"Weights\")\n",
        "        B = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"Biases\")\n",
        "\n",
        "        activation = tf.matmul(input, W) + B\n",
        "\n",
        "        tf.summary.histogram(\"weights\", W)\n",
        "        tf.summary.histogram(\"biases\", B)\n",
        "        tf.summary.histogram(\"activations\", activation)\n",
        "\n",
        "        return activation\n",
        "\n",
        "\n",
        "def model(mnist, learning_rate, epochs=2000):\n",
        "    \"\"\"Neural network model used in the MNIST dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mnist: TensorFlow dataset object\n",
        "        MNIST dataset loaded using TensorFlow.\n",
        "\n",
        "    learning_rate: float\n",
        "        Learning rate at which the network should\n",
        "        create momentum.\n",
        "\n",
        "    epochs: int, default 2000\n",
        "        Number of epochs to train the model with.\n",
        "    \"\"\"\n",
        "    name = \"MNIST-model/lr={}-epochs={}\".format(learning_rate, epochs)\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "    sess = tf.Session()\n",
        "\n",
        "    X = tf.placeholder(tf.float32, shape=[None, 784], name=\"X\")\n",
        "    X_image = tf.reshape(X, [-1, 28, 28, 1])\n",
        "    tf.summary.image('input', X_image, 3)\n",
        "\n",
        "    Y = tf.placeholder(tf.float32, shape=[None, 10], name=\"Labels\")\n",
        "\n",
        "    #\n",
        "    #  Convolutional layer treatment. We use a single convolutional layer.\n",
        "    #\n",
        "    convolution = convolutional_layer(X_image, 1, 64, \"Convolution_Layer\")\n",
        "    convolution_output = tf.nn.max_pool(convolution, ksize=[1, 2, 2, 1],\n",
        "                                        strides=[1, 2, 2, 1], padding=\"SAME\")\n",
        "\n",
        "    flattened = tf.reshape(convolution_output, [-1, 7 * 7 * 64])\n",
        "\n",
        "    #\n",
        "    #  Fully-connected layer treatment.\n",
        "    #  We will use two fully connected layers\n",
        "    #  that connect to each other. We can\n",
        "    #  try more or less to see the impact\n",
        "    #  on our model.\n",
        "    #\n",
        "    fully_connected_1 = fully_connected_layer(flattened, 7 * 7 * 64, 1024,\n",
        "                                              \"Fully-connected_Layer_1\")\n",
        "    relu = tf.nn.relu(fully_connected_1)\n",
        "    embedding_input = relu\n",
        "    tf.summary.histogram(\"Fully-connected_Layer-1/relu\", relu)\n",
        "\n",
        "    embedding_size = 1024\n",
        "    logits = fully_connected_layer(fully_connected_1, 1024, 10,\n",
        "                                   \"Fully-connected_Layer_2\")\n",
        "\n",
        "    with tf.name_scope(\"Cross_Entropy\"):\n",
        "        cross_entropy = tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(\n",
        "                logits=logits, labels=Y), name=\"cross_entropy\")\n",
        "\n",
        "        tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
        "\n",
        "    with tf.name_scope(\"Train\"):\n",
        "        train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
        "\n",
        "    with tf.name_scope(\"Accuracy\"):\n",
        "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "        tf.summary.scalar(\"Accuracy\", accuracy)\n",
        "\n",
        "    summ = tf.summary.merge_all()\n",
        "\n",
        "    #\n",
        "    #  Let's save embeddings so that they\n",
        "    #  are available in TensorBoard.\n",
        "    #\n",
        "    embedding = tf.Variable(tf.zeros([1024, embedding_size]), name=\"Test_Embedding\")\n",
        "    assignment = embedding.assign(embedding_input)\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    #\n",
        "    #  We can now run our TensorFlow session.\n",
        "    #\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    writer = tf.summary.FileWriter(LOGDIR + name)\n",
        "    writer.add_graph(sess.graph)\n",
        "\n",
        "    config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
        "    embedding_config = config.embeddings.add()\n",
        "    embedding_config.tensor_name = embedding.name\n",
        "    embedding_config.sprite.image_path = SPRITES\n",
        "    embedding_config.metadata_path = LABELS\n",
        "\n",
        "    #\n",
        "    #  Create each thumbnail.\n",
        "    #\n",
        "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
        "    tf.contrib.tensorboard.plugins.projector.visualize_embeddings(writer, config)\n",
        "\n",
        "    for i in tqdm.tqdm(range(epochs + 1), 'Epochs'):\n",
        "        batch = mnist.train.next_batch(100)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={X: batch[0], Y: batch[1]})\n",
        "            writer.add_summary(s, i)\n",
        "        if i % 500 == 0:\n",
        "            sess.run(assignment, feed_dict={\n",
        "                X: mnist.test.images[:1024],\n",
        "                Y: mnist.test.labels[:1024]\n",
        "            })\n",
        "            saver.save(sess, os.path.join(LOGDIR, \"model.ckpt\"), i)\n",
        "\n",
        "        sess.run(train_step, feed_dict={X: batch[0], Y: batch[1]})\n",
        "\n",
        "    print('\\nDone training!')\n",
        "    print('Run `tensorboard --logdir=%s` to see the results.' % LOGDIR)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main runner function.\n",
        "\n",
        "    This calls the model function.\n",
        "    \"\"\"\n",
        "    print(\"\"\"\n",
        "    Running MNIST model with:\n",
        "\n",
        "        * Learning rate: {}\n",
        "        * Epochs: {}\n",
        "\n",
        "    \"\"\".format(LEARNING_RATE, EPOCHS))\n",
        "\n",
        "    mnist = load_data()\n",
        "    model(mnist=mnist, learning_rate=LEARNING_RATE, epochs=EPOCHS)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    Running MNIST model with:\n",
            "\n",
            "        * Learning rate: 0.0001\n",
            "        * Epochs: 2000\n",
            "\n",
            "    \n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting mnist_example/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting mnist_example/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist_example/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist_example/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epochs: 100%|██████████| 2001/2001 [08:29<00:00,  3.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done training!\n",
            "Run `tensorboard --logdir=mnist_example/` to see the results.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycCKKubzb7bl",
        "outputId": "39dcc815-c3f4-42f6-842e-2c20b24662a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "tensorboard --logdir=mnist_example/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-e00b191a3346>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir=mnist_example/\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}